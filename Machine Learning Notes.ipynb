{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starter\n",
    "1. 資料格式壓縮(減少記憶體使用)\n",
    "2. to_feather(fast_loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA 資料探勘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 缺少值探勘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 視覺化 Sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多變量圖(pairplot)\n",
    "sns.pairplot(df['col1'],df['col2'],df['col3'],df['col4'])\n",
    "# 直方圖(含KDE)(distplot)\n",
    "sns.distplot(df['col1'])\n",
    "# 純KDE\n",
    "sns.kdeplot(df['col1'])\n",
    "# 視覺化風格\n",
    "plt.style.use('ggplot')\n",
    "# 直接用散狀圖幫你畫出線性迴歸趨勢! Great!\n",
    "sns.regplot(x=\"total_bill\", y=\"tip\", data=tips);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF \n",
    "#ECDF：累積分佈函數\n",
    "cdf = ECDF(df[\"特定資料函位\"])\n",
    "plt.plot(cdf.x, cdf.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徵工程(資料前處理)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 編碼\n",
    "> 處理物件或非數值欄位\n",
    "1. 標籤編碼(有序離散值) 請用Label Encoder\n",
    "2. 無序離散值用One Hot Encoder(小心特徵爆炸)\n",
    "3. 二值化(label_binarize)\n",
    "4. 計數編碼(Counting) 跟筆數有正相關，例如交易幾筆\n",
    "5. 均值編碼(Mean Encoding) - 與target有關，就用該類的avg target編碼\n",
    "> 注意 由於是用target的data leak，很容易overfitting，資料筆數過少時，容易被極端值影響，務必CV\n",
    "6. 雜湊編碼\n",
    "7. 群聚編碼: 是特徵彼此之間的augment(標籤->數值)mean, count等等去編碼\n",
    "> 群聚編碼因為與目標值無關，因此不容易 Overfitting\n",
    "8. 基於樹狀的葉編碼(LEAF ENCODING)\n",
    "> 先跑過一次模型用樹的分類當作特徵，有點BOOSTING的味道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with Objects\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Label Encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(app_train[col])\n",
    "app_train[col] = le.transform(app_train[col])\n",
    "# One Hot Encoder\n",
    "#get_dummies : 僅能將字串轉換為One hot encoding表示形式， 沒指定columns會全部轉換。\n",
    "app_train = pd.get_dummies(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增加編碼(feature augment)\n",
    "- 時間 - 常用(日/月/周/假日)\n",
    "- 地點 - 經緯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_month'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strftime(x, '%m')).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 離散化\n",
    "> 提升計算效率，降低outlier影響\n",
    "- 等寬、等頻\n",
    "- kmeans/二值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = pd.DataFrame({\"age\": [18,22,25,27,7,21,23,37,30,61,45,41,9,18,80,100]})\n",
    "ages[\"equal_width_age\"] = pd.cut(ages[\"age\"], 4) # 等寬劃分\n",
    "ages[\"equal_freq_age\"] = pd.qcut(ages[\"age\"], 4) # 等頻劃分\n",
    "ages.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 補缺值(平均/中位數或NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "# 填補器 : 設定缺失值補中位數\n",
    "imputer = Imputer(strategy = 'median')\n",
    "# 填補器載入個欄中位數\n",
    "imputer.fit(train)\n",
    "# 將中位數回填 train, test 資料中的空缺值\n",
    "train = imputer.transform(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 無量綱化\n",
    "- 歸一化-區間縮放或標準化[參考](https://medium.com/ai%E5%8F%8D%E6%96%97%E5%9F%8E/preprocessing-data-%E6%95%B8%E6%93%9A%E7%89%B9%E5%BE%B5%E6%A8%99%E6%BA%96%E5%8C%96%E5%92%8C%E6%AD%B8%E4%B8%80%E5%8C%96-9bd3e5a8f2fc)\n",
    "- 加速訓練，特別是深度學習前，必須歸一化，否則很難收斂(橢圓與圓形的梯度下降)\n",
    "- 使各特徵均衡(不被平方差大的主導)\n",
    "- 歸一化要注意，會被異常值影響(例如很大的Outlier): 應用 影像辨識/255\n",
    "- 標準化大多時間較好(符合統計+高斯分布 無量綱)\n",
    "- 幾乎都要做歸一或標準化 情境如下\n",
    "1. 有L1 L2正則化\n",
    "2. 有做PCA\n",
    "3. SVM、 SGD、linear/logistic regression 、Kmeans、KNN、NN（如果有用L1/L2 regularization）涉及到距離有關的算法\n",
    "- DecisionTree 、0/1取值的特徵、 基於平方損失的最小二乘法OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 歸一化物件導向\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler.fit(train)\n",
    "train = scaler.transform(train)\n",
    "\n",
    "# Normalization = MinMaxScaler\n",
    "(value - min(value) ) / ( max(value) - min(value) )\n",
    "\n",
    "# Standardization z-score 標準化 \n",
    "value - np.mean(value) / ( np.std(value) )\n",
    "def z_transform(x):\n",
    "    x = (x - np.mean(x)) / np.std(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理Large Skewness的方法\n",
    "- 注意np.log1p的使用，使target可以符合標準分布\n",
    "- log1p = log（x+1） 保證x很小時，還是不為0，反運算exmp1()\n",
    "- boxcox也是一種方式\n",
    "- 去除極端Outlier有助於訓練過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#離群值限制範圍\n",
    "df['GrLivArea'] = df['GrLivArea'].clip(500, 2000)\n",
    "#直接把離群值丟掉\n",
    "# 使用布林函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徵篩選\n",
    "- [知乎神文](https://www.zhihu.com/question/28641663/answer/110165221)\n",
    "1. 過濾法 (Filter) : \n",
    "- 相關係數過濾法(篩feature與target的相關係數)\n",
    "- 變異數過濾法(篩去小變異的\n",
    "2. 包裝法 (Wrapper) : 根據目標函數，逐步加入特徵或刪除特徵\n",
    "> 使用預測模型給特徵子集打分。每個新子集都被用來訓練一個模型，然後用驗證數據集來測試。通過計算驗證數據集上的錯誤次數（即模型的錯誤率）給特徵子集評分。由於包裝類方法為每個特徵子集訓練一個新模型，所以計算量很大。不過，這類方法往往能為特定類型的模型找到性能最好的特徵集。\n",
    "\n",
    "\n",
    "3. 嵌入法 (Embedded) : 使用機器學習模型，根據擬合後的係數，刪除係數低於門檻的特徵\n",
    "- 基於逞罰: L1(Lasso)嵌入法: 調整正規化程度(逞罰) 讓某些擬合參數變為0，刪除0的\n",
    "- 基於模型: GDBT(梯度提升樹)嵌入法: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "#####1#####\n",
    "#變異數\n",
    "VarianceThreshold(threshold=3).fit_transform(iris.data)\n",
    "#相關係數\n",
    "SelectKBest(lambda X, Y: array(map(lambda x:pearsonr(x, Y), X.T)).T, k=2).fit_transform(iris.data, iris.target)\n",
    "#卡方檢驗 - 檢查特徵與目標的相關性 - 計算不相干的值與實際值之平方差 HO假設\n",
    "SelectKBest(chi2, k=2).fit_transform(iris.data, iris.target)\n",
    "\n",
    "#####2#####\n",
    "RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)\n",
    "\n",
    "#####3#####\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#L1\n",
    "SelectFromModel(LogisticRegression(penalty=\"l1\", C=0.1)).fit_transform(iris.data, iris.target)\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#GBDT\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用梯度提升樹去套模型 選.feature_importances\n",
    "- 可利用特徵組合方法，把最重要的幾個特徵加減乘除做運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度提升樹擬合後, 將結果依照重要性由高到低排序\n",
    "estimator = GradientBoostingRegressor()\n",
    "estimator.fit(df.values, train_Y)\n",
    "# estimator.feature_importances_ 就是模型的特徵重要性, 這邊先與欄位名稱結合起來, 才能看到重要性與欄位名稱的對照表\n",
    "feats = pd.Series(data=estimator.feature_importances_, index=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切分資料\n",
    "- train_split\n",
    "- kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LASSO, Ridge Regression\n",
    "- Lasso 為 Linear Regression 加上 L1，Ridge 為 Linear Regression 加上 L2，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression #線性迴歸\n",
    "from sklearn.linear_model import LogisticRegression #分類問題\n",
    "\n",
    "\n",
    "# 設定模型與模型參數\n",
    "estimator = LogisticRegression(C = 0.0001)\n",
    "# 使用 Train 資料訓練模型\n",
    "estimator.fit(train, train_labels)\n",
    "pred = estimator.predict(test_X)\n",
    "log_reg_pred = estimator.predict_proba(test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K-fold CV\n",
    "- 交叉拆成K份，每次留一份當驗證集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "scores = cross_val_score(knn,X,y,cv=5,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失函數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 回歸常用的損失函數: 均方誤差(Mean square error，MSE)和平均絕對值誤差(Mean absolute error，MAE)。分類問題常用的損失函數: 交叉熵(cross-entropy)\n",
    "- 分類常用損失函數：\n",
    "- AUC\n",
    "- F1-Score (Precision, Recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
